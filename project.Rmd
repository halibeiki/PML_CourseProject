---
title: "Practical Machine Learning: Course Project (Prediction Assignment Writeup)"
author: "Hedayat Alibeiki"
output: html_document
---

## Background
It is now possible to collect a large amount of data about personal activity relatively inexpensively with quantified Self devices . The goal of this project is to utilize a sample data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants and then predict the manner in which they did the exercise. 

## Analysis
In this analysis we build a machine learning model from the sample data with the aim to accurately predict the manner in which the exercises were done. This is a classification problem with discrete categories: the 'classe' varaible in traning data.

### Loading Data and Preprocess
The first step in the project is to download the data to the directory. There are 2 data sets, the training data set and the testing data set. We do predict testing data using the final model that is based on training data. When the data is loaded into dataframes, it is necessary to locate strings containing '#DIV/0!', which is a common error code for division by zero. These error codes are loaded into the data frame as NA fields. The follwoing code chunk will perform these tasks.
```{r}
library(caret, quietly=TRUE)
adrs_train <- 'https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv'
adrs_test <- 'https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv'
#download.file(url = adrs_train, destfile = 'data_train.csv')
#download.file(url = adrs_test, destfile = 'data_test.csv')
pml_train <- read.csv(file = 'data_train.csv',
                      na.strings = c('NA','#DIV/0!',''))
pml_test <- read.csv(file = 'data_test.csv',
                     na.strings = c('NA','#DIV/0!',''))
```
The exploratory analysis shows that the first 7 dimensional fields of the data may not be relevant to the prediction model. The balance of the fields are numeric according to the data documentation available online. We do this through a "for loop" for all other columns except for "classe", which is the categorical variable that the prediction model is to classify it.

```{r,echo=TRUE}
for(i in c(8:ncol(pml_train)-1)) {
  pml_train[,i] = as.numeric(as.character(pml_train[,i]))
  pml_test[,i] = as.numeric(as.character(pml_test[,i]))
}
```
Further analysis reveals that of the many variables, several are very irrelevant and thus may not be as useful for building a classification model. The following code removes the columns with null values, and also removes the inital seven columns of dimensional data. From now on, we use this vector of column names as the main index into the training data, cross-validation data, and the testing data when interacting with a model.

```{r}
feature_index <- colnames(pml_train)
feature_index <- colnames(pml_train[colSums(is.na(pml_train)) == 0])
feature_index <- feature_index[-c(1:7)]

```

### Divide Data to Testing and Cross-Validation sets
To find an optimal model, with the best performance in both In-sample Accuracy  and Out of Sample Error, the full testing data is split randomly with a set seed with 80% of the data into the training sample and 20% of the data used as cross-validation. When the samples are created, we only use the columns of interest to make sure that only relevant features are considered into the final model.

```{r}
set.seed(800)
index_train <- createDataPartition(y=pml_train$classe, p=0.80, list=FALSE)
data_train <- pml_train[index_train,feature_index]
data_xval <- pml_train[-index_train,feature_index]
dim(data_train); dim(data_xval)
```

### Closer Look at Frequency of Each Class (distribution examination)

Before choosing a model to fit the data, it is useful to have an idea that what is the total expected proportion of each classification variable outcome in the prediction. This wil help us to optimize models for Specificity, Sensitivity, and Positive/Negative Predictive Value. 

```{r}
plot(data_train$classe, main="Histogram of Classe in Traning Data", xlab="Classe of Excercise", ylab="Frequency in Training Data")
```

The above plot shows that each of the classifications are roughly as likely as any other to happen. This indicates that optimizing a model for accuracy and minimizing overall out of sample error should indicate an optimal model for making classificions.

### Training Model and Cross Validating

From the previous analyses, we choose a Random Forest model to fit the data and predict "classe".

```{r,echo=TRUE,results='hide'}
mod_rf <- train(classe ~ .,
                data = data_train, 
                method = 'rf', 
                trControl = trainControl(method = "cv", 
                                         number = 4, 
                                         allowParallel = TRUE, 
                                         verboseIter = TRUE))
pred_rf <- predict(mod_rf,data_xval)
cm_rf <- confusionMatrix(pred_rf,data_xval$classe)
```

#### Predictions on Cross Validation Data

For each candidate model, predictions are made agaist the cross-validation data set. Then, a confusion matrix is calculated and stored for each model for later reference. The confusion matrix in fact demonstrates the accuracy of the model by comparing the predictions for each class against the actual value in the cross validation set.

The *Random Forest model* appears to be the most accurate.  The intersection of the same value for Predicted Classe and Actual Class is very high for all 5 classes in the Random Forest model, indicating that the model is highly accurate, both overall as well as within each class.


```{r}
cm_rf
```

The accuracy of the model is 0.9944. The out of sample error is 0.0056. Considering that the test set is a sample size of 20, an accuracy rate well above 99% is sufficient to expect that few or none of the test samples will be mis-classified.

## Applying Trained Model to the Test Set

For the test results, there are 20 samples asked to be classified. We first make sure that the column names are consistent between the test and training data by renaming the last column in the testing set for compatability purpose. Once the predictions are made from the chosen Random Forest model, the prediction vector is shown.

```{r}
final_col <- length(colnames(pml_test[]))
colnames(pml_test)[final_col] <- 'classe'
test_rf <- predict(mod_rf,pml_test[,feature_index])
test_rf

```

